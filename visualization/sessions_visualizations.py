import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from config.settings import Settings

def mostrar_exit_pages_analysis(df):
    """Visualizaci√≥n para Most Frequent Exit Pages Analysis"""
    st.subheader("üö™ An√°lisis de P√°ginas de Salida")
    
    if df.empty:
        st.warning("No hay datos de p√°ginas de salida para el rango seleccionado")
        return
    
    # M√©tricas generales
    total_sessions = df['sessions'].sum()
    unique_exit_pages = len(df)
    avg_sessions_per_page = df['sessions'].mean()
    top_exit_rate = df.iloc[0]['exit_percentage'] if len(df) > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Sesiones", f"{total_sessions:,}")
    with col2:
        st.metric("P√°ginas de Salida √önicas", f"{unique_exit_pages}")
    with col3:
        st.metric("Sesiones/P√°gina (Avg)", f"{avg_sessions_per_page:.0f}")
    with col4:
        st.metric("Mayor % Salida", f"{top_exit_rate:.1f}%")
    
    # Acortar URLs para mejor visualizaci√≥n
    def shorten_url(url, max_length=60):
        if pd.isna(url):
            return "(not set)"
        return url[:max_length] + '...' if len(str(url)) > max_length else url
    
    df['exit_page_short'] = df['exit_page_path'].apply(shorten_url)
    
    # Filtro por n√∫mero m√≠nimo de sesiones
    st.subheader("üîç Filtros")
    
    col1, col2 = st.columns(2)
    with col1:
        min_sessions_filter = st.slider(
            "M√≠nimo de sesiones:",
            min_value=1,
            max_value=int(df['sessions'].max()) if len(df) > 0 else 100,
            value=10,
            key="exit_min_sessions"
        )
    
    with col2:
        top_n = st.selectbox(
            "Mostrar top:",
            [10, 20, 30, 50, 100],
            index=1,
            key="exit_top_n"
        )
    
    # Aplicar filtros
    df_filtered = df[df['sessions'] >= min_sessions_filter].head(top_n)
    
    if df_filtered.empty:
        st.warning("‚ö†Ô∏è No hay datos con los filtros seleccionados. Reduce el m√≠nimo de sesiones.")
        return
    
    # Mostrar tabla con datos
    st.subheader("üìä Datos Detallados")
    
    st.dataframe(
        df_filtered[['exit_page_path', 'sessions', 'exit_percentage']].style.format({
            'sessions': '{:,}',
            'exit_percentage': '{:.2f}%'
        }),
        use_container_width=True,
        height=400
    )
    
    # Top p√°ginas de salida
    st.subheader(f"üèÜ Top {min(top_n, len(df_filtered))} P√°ginas de Salida")
    
    top_exits = df_filtered.head(top_n)
    
    fig_top_exits = px.bar(
        top_exits,
        x='sessions',
        y='exit_page_short',
        orientation='h',
        title=f'Top {min(top_n, len(top_exits))} P√°ginas con Mayor Abandono',
        labels={'sessions': 'Sesiones', 'exit_page_short': 'P√°gina de Salida'},
        color='exit_percentage',
        color_continuous_scale='Reds',
        hover_data={'exit_page_path': True, 'exit_percentage': ':.2f'}
    )
    fig_top_exits.update_layout(
        yaxis={'categoryorder': 'total ascending'},
        height=max(500, len(top_exits) * 25),
        showlegend=False
    )
    st.plotly_chart(fig_top_exits, use_container_width=True)
    
    # Distribuci√≥n acumulativa
    st.subheader("üìà An√°lisis de Concentraci√≥n")
    
    # Calcular porcentaje acumulativo
    df_sorted = df.sort_values('sessions', ascending=False).reset_index(drop=True)
    df_sorted['cumulative_sessions'] = df_sorted['sessions'].cumsum()
    df_sorted['cumulative_percentage'] = (df_sorted['cumulative_sessions'] / total_sessions * 100).round(2)
    
    # Gr√°fico de Pareto
    fig_pareto = go.Figure()
    
    fig_pareto.add_trace(go.Bar(
        x=list(range(1, len(df_sorted.head(30)) + 1)),
        y=df_sorted.head(30)['sessions'],
        name='Sesiones',
        marker_color='lightblue',
        yaxis='y'
    ))
    
    fig_pareto.add_trace(go.Scatter(
        x=list(range(1, len(df_sorted.head(30)) + 1)),
        y=df_sorted.head(30)['cumulative_percentage'],
        name='% Acumulado',
        mode='lines+markers',
        line=dict(color='red', width=2),
        yaxis='y2'
    ))
    
    fig_pareto.update_layout(
        title='An√°lisis de Pareto - Concentraci√≥n de Salidas (Top 30)',
        xaxis_title='P√°ginas (ordenadas por sesiones)',
        yaxis=dict(title='Sesiones', side='left'),
        yaxis2=dict(title='% Acumulado', side='right', overlaying='y', range=[0, 100]),
        hovermode='x unified',
        height=500
    )
    
    st.plotly_chart(fig_pareto, use_container_width=True)
    
    # M√©tricas de concentraci√≥n
    top_10_pct = df_sorted.head(10)['exit_percentage'].sum()
    top_20_pct = df_sorted.head(20)['exit_percentage'].sum()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Top 10 P√°ginas", f"{top_10_pct:.1f}% de salidas")
    with col2:
        st.metric("Top 20 P√°ginas", f"{top_20_pct:.1f}% de salidas")
    with col3:
        # Calcular √≠ndice de concentraci√≥n (cu√°ntas p√°ginas acumulan el 80%)
        pages_80pct = len(df_sorted[df_sorted['cumulative_percentage'] <= 80])
        st.metric("P√°ginas para 80% salidas", f"{pages_80pct}")
    
    # Distribuci√≥n de p√°ginas de salida
    st.subheader("üìä Distribuci√≥n de Sesiones")
    
    # Crear rangos de sesiones
    df_filtered['session_range'] = pd.cut(
        df_filtered['sessions'],
        bins=[0, 50, 100, 500, 1000, float('inf')],
        labels=['1-50', '51-100', '101-500', '501-1000', '1000+']
    )
    
    range_dist = df_filtered.groupby('session_range', observed=True).size().reset_index(name='count')
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Pie chart de distribuci√≥n por rango
        fig_dist = px.pie(
            range_dist,
            values='count',
            names='session_range',
            title='Distribuci√≥n de P√°ginas por Rango de Sesiones',
            color_discrete_sequence=px.colors.sequential.RdBu
        )
        st.plotly_chart(fig_dist, use_container_width=True)
    
    with col2:
        # Histograma de sesiones
        fig_hist = px.histogram(
            df_filtered,
            x='sessions',
            nbins=30,
            title='Distribuci√≥n de Sesiones por P√°gina',
            labels={'sessions': 'Sesiones', 'count': 'N√∫mero de P√°ginas'},
            color_discrete_sequence=['steelblue']
        )
        fig_hist.update_layout(showlegend=False)
        st.plotly_chart(fig_hist, use_container_width=True)
    
    # An√°lisis de patrones en URLs
    st.subheader("üîç An√°lisis de Patrones de URL")
    
    # Extraer secciones del sitio (primer nivel de path)
    df_filtered['section'] = df_filtered['exit_page_path'].str.extract(r'^/([^/]+)')[0].fillna('home')
    
    section_stats = df_filtered.groupby('section').agg({
        'sessions': 'sum',
        'exit_page_path': 'count'
    }).reset_index()
    section_stats.columns = ['section', 'total_sessions', 'page_count']
    section_stats = section_stats.sort_values('total_sessions', ascending=False).head(15)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Sesiones por secci√≥n
        fig_sections = px.bar(
            section_stats,
            x='section',
            y='total_sessions',
            title='Sesiones de Salida por Secci√≥n del Sitio',
            labels={'section': 'Secci√≥n', 'total_sessions': 'Sesiones'},
            color='total_sessions',
            color_continuous_scale='Oranges'
        )
        fig_sections.update_layout(xaxis_tickangle=-45, showlegend=False)
        st.plotly_chart(fig_sections, use_container_width=True)
    
    with col2:
        # Tabla de secciones
        st.write("**Top Secciones con M√°s Salidas:**")
        st.dataframe(
            section_stats[['section', 'total_sessions', 'page_count']].style.format({
                'total_sessions': '{:,}',
                'page_count': '{:,}'
            }),
            use_container_width=True
        )
    
    # Insights y recomendaciones
    st.subheader("üí° Insights Clave")
    
    # Identificar p√°ginas cr√≠ticas
    top_exit = df_sorted.iloc[0] if len(df_sorted) > 0 else None
    high_exit_pages = df_sorted[df_sorted['exit_percentage'] > 5].head(10)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**üö® P√°gina con Mayor Abandono:**")
        if top_exit is not None:
            st.write(f"- **P√°gina:** {shorten_url(top_exit['exit_page_path'], 50)}")
            st.write(f"- **Sesiones:** {top_exit['sessions']:,}")
            st.write(f"- **% del Total:** {top_exit['exit_percentage']:.2f}%")
    
    with col2:
        st.write("**‚ö†Ô∏è P√°ginas Cr√≠ticas (>5% salidas):**")
        if not high_exit_pages.empty:
            for _, row in high_exit_pages.iterrows():
                st.write(f"- {shorten_url(row['exit_page_path'], 40)}: {row['exit_percentage']:.1f}%")
        else:
            st.write("‚úÖ No hay p√°ginas individuales con >5% de salidas")
    
    # Recomendaciones
    st.subheader("üéØ Recomendaciones")
    
    st.info(f"""
    **Plan de Acci√≥n para Reducir Abandonos:**
    
    üîç **Priorizar optimizaci√≥n:**
    - Las top {pages_80pct} p√°ginas concentran el 80% de las salidas
    - Enfoca esfuerzos en estas p√°ginas para mayor impacto
    
    üéØ **P√°ginas cr√≠ticas identificadas:**
    - {len(high_exit_pages)} p√°ginas con >5% de tasa de salida
    - Requieren revisi√≥n urgente de UX y contenido
    
    ‚ö° **Acciones recomendadas:**
    1. Analizar tiempo en p√°gina antes de salir
    2. Revisar llamadas a la acci√≥n (CTAs)
    3. Verificar errores t√©cnicos o problemas de carga
    4. A/B testing en p√°ginas con mayor abandono
    5. Agregar contenido relacionado o next steps claros
    
    üí∞ **Impacto potencial:**
    - Reducir un 10% las salidas de las top 10 p√°ginas podr√≠a retener ~{int(df_sorted.head(10)['sessions'].sum() * 0.1):,} sesiones adicionales
    """)
    
    # Comparativa: P√°ginas de entrada vs salida
    st.subheader("üîÑ Insight Adicional")
    
    # Identificar p√°ginas que son tanto entrada como salida
    entrance_keywords = ['home', 'index', 'landing', 'categoria', 'product']
    potential_entrance_exits = df_filtered[
        df_filtered['exit_page_path'].str.contains('|'.join(entrance_keywords), case=False, na=False)
    ]
    
    if not potential_entrance_exits.empty:
        st.warning(f"""
        **‚ö†Ô∏è P√°ginas que pueden ser tanto entrada como salida:**
        
        Se detectaron {len(potential_entrance_exits)} p√°ginas que parecen ser landing pages pero tambi√©n tienen alta tasa de salida.
        
        Esto puede indicar:
        - Problemas de expectativas vs realidad
        - Falta de contenido relevante
        - Problemas t√©cnicos en la primera interacci√≥n
        
        **P√°ginas a revisar:**
        """)
        
        for _, row in potential_entrance_exits.head(5).iterrows():
            st.write(f"- {shorten_url(row['exit_page_path'], 60)}: {row['sessions']:,} salidas ({row['exit_percentage']:.1f}%)")
    
    # Bot√≥n de descarga
    if st.button("üì• Descargar Datos CSV", key="download_exit_pages"):
        csv = df.to_csv(index=False)
        st.download_button(
            label="Descargar CSV",
            data=csv,
            file_name="exit_pages_analysis.csv",
            mime="text/csv"
        )

def mostrar_hourly_sessions_performance(df):
    """Visualizaci√≥n para Hourly Sessions Ecommerce Performance"""
    st.subheader("‚è∞ Rendimiento de Sesiones por Hora")
    
    if df.empty:
        st.warning("No hay datos de rendimiento horario para el rango seleccionado")
        return
    
    # Convertir hora a entero para mejor ordenamiento
    df['hour_int'] = df['hour'].astype(int)
    
    # M√©tricas generales
    total_sessions = df['sessions'].sum()
    total_pageviews = df['pageviews'].sum()
    total_orders = df['order_sessions'].sum()
    avg_sessions_per_hour = df['sessions'].mean()
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Sesiones", f"{total_sessions:,}")
    with col2:
        st.metric("Total Pageviews", f"{total_pageviews:,}")
    with col3:
        st.metric("Total Compras", f"{total_orders:,}")
    with col4:
        st.metric("Sesiones/Hora (Avg)", f"{avg_sessions_per_hour:.0f}")
    
    # Calcular tasas de conversi√≥n por hora
    df['view_item_rate'] = (df['view_item_sessions'] / df['sessions'] * 100).round(2)
    df['add_to_cart_rate'] = (df['add_to_cart_sessions'] / df['sessions'] * 100).round(2)
    df['conversion_rate'] = (df['order_sessions'] / df['sessions'] * 100).round(2)
    
    # Agregar por hora del d√≠a (promedio de todas las fechas)
    hourly_avg = df.groupby('hour_int').agg({
        'sessions': 'mean',
        'pageviews': 'mean',
        'view_item_sessions': 'mean',
        'add_to_cart_sessions': 'mean',
        'order_sessions': 'mean',
        'view_item_rate': 'mean',
        'add_to_cart_rate': 'mean',
        'conversion_rate': 'mean'
    }).reset_index()
    
    hourly_avg['hour'] = hourly_avg['hour_int'].apply(lambda x: f'{x:02d}:00')
    
    # An√°lisis por hora del d√≠a
    st.subheader("üìä Distribuci√≥n por Hora del D√≠a")
    
    # Gr√°fico de l√≠neas - Sesiones y eventos por hora
    fig_hourly = go.Figure()
    
    fig_hourly.add_trace(go.Scatter(
        x=hourly_avg['hour'],
        y=hourly_avg['sessions'],
        name='Sesiones',
        mode='lines+markers',
        line=dict(color='blue', width=3),
        yaxis='y'
    ))
    
    fig_hourly.add_trace(go.Scatter(
        x=hourly_avg['hour'],
        y=hourly_avg['view_item_sessions'],
        name='View Item',
        mode='lines+markers',
        line=dict(color='green', width=2),
        yaxis='y'
    ))
    
    fig_hourly.add_trace(go.Scatter(
        x=hourly_avg['hour'],
        y=hourly_avg['add_to_cart_sessions'],
        name='Add to Cart',
        mode='lines+markers',
        line=dict(color='orange', width=2),
        yaxis='y'
    ))
    
    fig_hourly.add_trace(go.Scatter(
        x=hourly_avg['hour'],
        y=hourly_avg['order_sessions'],
        name='Compras',
        mode='lines+markers',
        line=dict(color='red', width=2),
        yaxis='y2'
    ))
    
    fig_hourly.update_layout(
        title='Actividad por Hora del D√≠a (Promedio)',
        xaxis_title='Hora del D√≠a',
        yaxis=dict(title='Sesiones / Eventos'),
        yaxis2=dict(title='Compras', overlaying='y', side='right'),
        hovermode='x unified',
        height=500
    )
    
    st.plotly_chart(fig_hourly, use_container_width=True)
    
    # Heatmap de actividad por hora y d√≠a de la semana
    st.subheader("üî• Heatmap: Actividad por D√≠a y Hora")
    
    # Preparar datos para heatmap
    heatmap_data = df.pivot_table(
        values='sessions',
        index='weekday',
        columns='hour_int',
        aggfunc='mean'
    )
    
    # Ordenar d√≠as de la semana correctamente
    weekday_order = ['0 - Sunday', '1 - Monday', '2 - Tuesday', '3 - Wednesday', 
                     '4 - Thursday', '5 - Friday', '6 - Saturday']
    
    # Filtrar solo los d√≠as que existen en los datos
    weekday_order = [day for day in weekday_order if day in heatmap_data.index]
    heatmap_data = heatmap_data.reindex(weekday_order)
    
    fig_heatmap = px.imshow(
        heatmap_data,
        labels=dict(x="Hora del D√≠a", y="D√≠a de la Semana", color="Sesiones"),
        title="Sesiones por D√≠a de la Semana y Hora",
        color_continuous_scale='Blues',
        aspect="auto"
    )
    fig_heatmap.update_xaxes(side="bottom")
    fig_heatmap.update_layout(height=400)
    
    st.plotly_chart(fig_heatmap, use_container_width=True)
    
    # An√°lisis de conversi√≥n por hora
    st.subheader("üí∞ Tasas de Conversi√≥n por Hora")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Gr√°fico de tasas de conversi√≥n
        fig_conversion = go.Figure()
        
        fig_conversion.add_trace(go.Bar(
            x=hourly_avg['hour'],
            y=hourly_avg['view_item_rate'],
            name='View Item Rate',
            marker_color='lightblue'
        ))
        
        fig_conversion.add_trace(go.Bar(
            x=hourly_avg['hour'],
            y=hourly_avg['add_to_cart_rate'],
            name='Add to Cart Rate',
            marker_color='lightgreen'
        ))
        
        fig_conversion.add_trace(go.Bar(
            x=hourly_avg['hour'],
            y=hourly_avg['conversion_rate'],
            name='Conversion Rate',
            marker_color='salmon'
        ))
        
        fig_conversion.update_layout(
            title='Tasas de Conversi√≥n por Hora',
            xaxis_title='Hora',
            yaxis_title='Tasa (%)',
            barmode='group',
            height=400
        )
        
        st.plotly_chart(fig_conversion, use_container_width=True)
    
    with col2:
        # Scatter: Sesiones vs Conversi√≥n
        fig_scatter = px.scatter(
            hourly_avg,
            x='sessions',
            y='conversion_rate',
            size='order_sessions',
            color='hour_int',
            hover_data=['hour'],
            title='Volumen vs Conversi√≥n por Hora',
            labels={
                'sessions': 'Sesiones Promedio',
                'conversion_rate': 'Tasa Conversi√≥n (%)',
                'order_sessions': 'Compras',
                'hour_int': 'Hora'
            },
            color_continuous_scale='Viridis'
        )
        fig_scatter.update_layout(height=400)
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    # An√°lisis por d√≠a de la semana
    st.subheader("üìÖ An√°lisis por D√≠a de la Semana")
    
    # Agregar por d√≠a de la semana
    weekday_avg = df.groupby('weekday').agg({
        'sessions': 'mean',
        'pageviews': 'mean',
        'view_item_sessions': 'mean',
        'add_to_cart_sessions': 'mean',
        'order_sessions': 'mean',
        'conversion_rate': 'mean'
    }).reset_index()
    
    # Reordenar d√≠as de la semana
    weekday_avg['weekday_sort'] = weekday_avg['weekday'].str.split(' - ').str[0].astype(int)
    weekday_avg = weekday_avg.sort_values('weekday_sort')
    weekday_avg['weekday_name'] = weekday_avg['weekday'].str.split(' - ').str[1]
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Sesiones por d√≠a de la semana
        fig_weekday_sessions = px.bar(
            weekday_avg,
            x='weekday_name',
            y='sessions',
            title='Sesiones Promedio por D√≠a de la Semana',
            labels={'sessions': 'Sesiones', 'weekday_name': 'D√≠a'},
            color='sessions',
            color_continuous_scale='Blues'
        )
        st.plotly_chart(fig_weekday_sessions, use_container_width=True)
    
    with col2:
        # Conversi√≥n por d√≠a de la semana
        fig_weekday_conv = px.bar(
            weekday_avg,
            x='weekday_name',
            y='conversion_rate',
            title='Tasa de Conversi√≥n por D√≠a',
            labels={'conversion_rate': 'Conversi√≥n (%)', 'weekday_name': 'D√≠a'},
            color='conversion_rate',
            color_continuous_scale='Reds'
        )
        st.plotly_chart(fig_weekday_conv, use_container_width=True)
    
    # Identificar mejores y peores horas
    st.subheader("üí° Insights: Mejores y Peores Horas")
    
    # Top 5 horas por sesiones
    top_hours_sessions = hourly_avg.nlargest(5, 'sessions')
    bottom_hours_sessions = hourly_avg.nsmallest(5, 'sessions')
    
    # Top 5 horas por conversi√≥n
    top_hours_conversion = hourly_avg.nlargest(5, 'conversion_rate')
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**üöÄ Top 5 Horas (Mayor Tr√°fico):**")
        for _, row in top_hours_sessions.iterrows():
            st.write(f"- **{row['hour']}**: {row['sessions']:.0f} sesiones")
    
    with col2:
        st.write("**üò¥ Top 5 Horas (Menor Tr√°fico):**")
        for _, row in bottom_hours_sessions.iterrows():
            st.write(f"- **{row['hour']}**: {row['sessions']:.0f} sesiones")
    
    with col3:
        st.write("**üí∞ Top 5 Horas (Mayor Conversi√≥n):**")
        for _, row in top_hours_conversion.iterrows():
            st.write(f"- **{row['hour']}**: {row['conversion_rate']:.2f}%")
    
    # Tabla detallada
    st.subheader("üìã Datos Detallados por Hora")
    
    display_df = hourly_avg[[
        'hour', 'sessions', 'pageviews', 'view_item_sessions', 
        'add_to_cart_sessions', 'order_sessions', 
        'view_item_rate', 'add_to_cart_rate', 'conversion_rate'
    ]].copy()
    
    st.dataframe(display_df.style.format({
        'sessions': '{:.0f}',
        'pageviews': '{:.0f}',
        'view_item_sessions': '{:.0f}',
        'add_to_cart_sessions': '{:.0f}',
        'order_sessions': '{:.0f}',
        'view_item_rate': '{:.2f}%',
        'add_to_cart_rate': '{:.2f}%',
        'conversion_rate': '{:.2f}%'
    }), use_container_width=True)
    
    # Recomendaciones
    st.subheader("üéØ Recomendaciones")
    
    peak_hour = top_hours_sessions.iloc[0]
    best_conversion_hour = top_hours_conversion.iloc[0]
    
    st.info(f"""
    **Optimizaci√≥n de Horarios:**
    
    - üïê **Hora pico de tr√°fico:** {peak_hour['hour']} con {peak_hour['sessions']:.0f} sesiones promedio
    - üí∞ **Mejor hora para conversi√≥n:** {best_conversion_hour['hour']} con {best_conversion_hour['conversion_rate']:.2f}% de conversi√≥n
    - üì¢ **Recomendaci√≥n:** Programa campa√±as de marketing y promociones durante las horas pico
    - ‚ö° **Consejo:** Asegura que el sitio est√© optimizado durante las horas de mayor tr√°fico
    """)
    
    # Bot√≥n de descarga
    if st.button("üì• Descargar Datos CSV", key="download_hourly_performance"):
        csv = df.to_csv(index=False)
        st.download_button(
            label="Descargar CSV",
            data=csv,
            file_name="hourly_sessions_performance.csv",
            mime="text/csv"
        )

def mostrar_session_path_analysis(df):
    """Visualizaci√≥n para Session Path Analysis - CON SANKEY MEJORADO"""
    st.subheader("üó∫Ô∏è An√°lisis de Rutas de Navegaci√≥n")
    
    if df.empty:
        st.warning("No hay datos de rutas de navegaci√≥n para el rango seleccionado")
        return
    
    # M√©tricas generales
    total_paths = len(df)
    total_sessions = df['session_count'].sum()
    unique_pages = pd.concat([df['previous_page'], df['current_page'], df['next_page']]).nunique()
    avg_sessions_per_path = df['session_count'].mean()
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Rutas √önicas", f"{total_paths:,}")
    with col2:
        st.metric("Total Sesiones", f"{total_sessions:,}")
    with col3:
        st.metric("P√°ginas √önicas", f"{unique_pages}")
    with col4:
        st.metric("Sesiones/Ruta (Avg)", f"{avg_sessions_per_path:.1f}")
    
    # Acortar URLs para mejor visualizaci√≥n
    def shorten_url(url, max_length=40):
        if pd.isna(url) or url == '(entrance)' or url == '(exit)':
            return url
        return url[:max_length] + '...' if len(str(url)) > max_length else url
    
    df['previous_page_short'] = df['previous_page'].apply(shorten_url)
    df['current_page_short'] = df['current_page'].apply(shorten_url)
    df['next_page_short'] = df['next_page'].apply(shorten_url)
    
    # Crear columna de ruta completa
    df['full_path'] = df['previous_page_short'] + ' ‚Üí ' + df['current_page_short'] + ' ‚Üí ' + df['next_page_short']
    
    # Mostrar tabla con datos
    st.subheader("üìä Top Rutas de Navegaci√≥n")
    
    # Opciones de filtrado
    col1, col2 = st.columns(2)
    with col1:
        min_sessions = st.slider(
            "M√≠nimo de sesiones por ruta:",
            min_value=1,
            max_value=int(df['session_count'].max()),
            value=10,
            key="path_min_sessions"
        )
    
    with col2:
        path_type = st.selectbox(
            "Filtrar por tipo de ruta:",
            ["Todas", "Solo entradas (entrance)", "Solo salidas (exit)", "Rutas internas"],
            key="path_type_filter"
        )
    
    # Aplicar filtros
    df_filtered = df[df['session_count'] >= min_sessions].copy()
    
    if path_type == "Solo entradas (entrance)":
        df_filtered = df_filtered[df_filtered['previous_page'] == '(entrance)']
    elif path_type == "Solo salidas (exit)":
        df_filtered = df_filtered[df_filtered['next_page'] == '(exit)']
    elif path_type == "Rutas internas":
        df_filtered = df_filtered[
            (df_filtered['previous_page'] != '(entrance)') & 
            (df_filtered['next_page'] != '(exit)')
        ]
    
    # Mostrar tabla
    st.dataframe(
        df_filtered[['previous_page', 'current_page', 'next_page', 'session_count']].head(50).style.format({
            'session_count': '{:,}'
        }),
        use_container_width=True,
        height=400
    )
    
    # Top 20 rutas m√°s comunes
    st.subheader("üèÜ Top 20 Rutas M√°s Comunes")
    
    top_paths = df_filtered.nlargest(20, 'session_count')
    
    fig_top_paths = px.bar(
        top_paths,
        x='session_count',
        y='full_path',
        orientation='h',
        title='Top 20 Rutas de Navegaci√≥n',
        labels={'session_count': 'Sesiones', 'full_path': 'Ruta'},
        color='session_count',
        color_continuous_scale='Blues'
    )
    fig_top_paths.update_layout(
        yaxis={'categoryorder': 'total ascending'},
        height=700,
        showlegend=False
    )
    st.plotly_chart(fig_top_paths, use_container_width=True)
    
    # An√°lisis de p√°ginas de entrada
    st.subheader("üö™ An√°lisis de P√°ginas de Entrada")
    
    entrance_pages = df[df['previous_page'] == '(entrance)'].groupby('current_page').agg({
        'session_count': 'sum'
    }).reset_index().sort_values('session_count', ascending=False).head(15)
    
    entrance_pages['current_page_short'] = entrance_pages['current_page'].apply(shorten_url)
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig_entrance = px.bar(
            entrance_pages,
            x='session_count',
            y='current_page_short',
            orientation='h',
            title='Top 15 P√°ginas de Entrada',
            labels={'session_count': 'Sesiones', 'current_page_short': 'P√°gina'},
            color='session_count',
            color_continuous_scale='Greens'
        )
        fig_entrance.update_layout(yaxis={'categoryorder': 'total ascending'}, height=500)
        st.plotly_chart(fig_entrance, use_container_width=True)
    
    with col2:
        # Pie chart de distribuci√≥n
        fig_entrance_pie = px.pie(
            entrance_pages.head(10),
            values='session_count',
            names='current_page_short',
            title='Distribuci√≥n Top 10 Entradas'
        )
        st.plotly_chart(fig_entrance_pie, use_container_width=True)
    
    # An√°lisis de p√°ginas de salida
    st.subheader("üö∂ An√°lisis de P√°ginas de Salida")
    
    exit_pages = df[df['next_page'] == '(exit)'].groupby('current_page').agg({
        'session_count': 'sum'
    }).reset_index().sort_values('session_count', ascending=False).head(15)
    
    exit_pages['current_page_short'] = exit_pages['current_page'].apply(shorten_url)
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig_exit = px.bar(
            exit_pages,
            x='session_count',
            y='current_page_short',
            orientation='h',
            title='Top 15 P√°ginas de Salida',
            labels={'session_count': 'Sesiones', 'current_page_short': 'P√°gina'},
            color='session_count',
            color_continuous_scale='Reds'
        )
        fig_exit.update_layout(yaxis={'categoryorder': 'total ascending'}, height=500)
        st.plotly_chart(fig_exit, use_container_width=True)
    
    with col2:
        # Tabla de p√°ginas de salida
        st.write("**P√°ginas con Mayor Abandono:**")
        st.dataframe(
            exit_pages[['current_page', 'session_count']].head(10).style.format({
                'session_count': '{:,}'
            }),
            use_container_width=True
        )
    
    # ========================================
    # SANKEY DIAGRAM MEJORADO
    # ========================================
    st.subheader("üîÑ Flujo de Navegaci√≥n (Sankey Diagram)")
    
    # Control de n√∫mero de rutas a mostrar
    col1, col2 = st.columns([3, 1])
    with col1:
        st.info("üí° **Tip**: Reduce el n√∫mero de rutas si el diagrama se ve sobrecargado")
    with col2:
        num_routes = st.selectbox(
            "Rutas a mostrar:",
            [10, 15, 20, 30, 50],
            index=2,  # Default: 20
            key="sankey_routes"
        )
    
    # Preparar datos para Sankey (Top N rutas m√°s comunes)
    sankey_data = df_filtered.nlargest(num_routes, 'session_count')
    
    # Crear nodos √∫nicos con prefijos para evitar colisiones
    # Estrategia: a√±adir sufijo _prev, _curr, _next a cada p√°gina seg√∫n su posici√≥n
    prev_pages = sankey_data['previous_page_short'].unique()
    curr_pages = sankey_data['current_page_short'].unique()
    next_pages = sankey_data['next_page_short'].unique()
    
    # Crear diccionarios de mapeo con sufijos para evitar duplicados
    prev_dict = {page: f"{page} [entrada]" if page == '(entrance)' else f"{page} ‚Üê" for page in prev_pages}
    curr_dict = {page: f"{page} [p√°gina]" for page in curr_pages}
    next_dict = {page: f"{page} [salida]" if page == '(exit)' else f"{page} ‚Üí" for page in next_pages}
    
    # Crear lista de todos los nodos √∫nicos
    all_nodes = []
    all_nodes.extend(prev_dict.values())
    all_nodes.extend([node for node in curr_dict.values() if node not in all_nodes])
    all_nodes.extend([node for node in next_dict.values() if node not in all_nodes])
    
    # Crear mapeo de √≠ndices
    node_indices = {node: idx for idx, node in enumerate(all_nodes)}
    
    # Crear links para el diagrama - PARTE 1: previous ‚Üí current
    source_indices_1 = []
    target_indices_1 = []
    values_1 = []
    
    for _, row in sankey_data.iterrows():
        prev_node = prev_dict[row['previous_page_short']]
        curr_node = curr_dict[row['current_page_short']]
        
        source_indices_1.append(node_indices[prev_node])
        target_indices_1.append(node_indices[curr_node])
        values_1.append(row['session_count'])
    
    # Crear links para el diagrama - PARTE 2: current ‚Üí next
    source_indices_2 = []
    target_indices_2 = []
    values_2 = []
    
    for _, row in sankey_data.iterrows():
        curr_node = curr_dict[row['current_page_short']]
        next_node = next_dict[row['next_page_short']]
        
        source_indices_2.append(node_indices[curr_node])
        target_indices_2.append(node_indices[next_node])
        values_2.append(row['session_count'])
    
    # Combinar ambas partes
    all_sources = source_indices_1 + source_indices_2
    all_targets = target_indices_1 + target_indices_2
    all_values = values_1 + values_2
    
    # Colores personalizados para nodos
    node_colors = []
    for node in all_nodes:
        if '[entrada]' in node or '(entrance)' in node:
            node_colors.append('rgba(76, 175, 80, 0.8)')  # Verde para entradas
        elif '[salida]' in node or '(exit)' in node:
            node_colors.append('rgba(244, 67, 54, 0.8)')  # Rojo para salidas
        else:
            node_colors.append('rgba(33, 150, 243, 0.8)')  # Azul para p√°ginas intermedias
    
    # Crear Sankey diagram MEJORADO
    fig_sankey = go.Figure(data=[go.Sankey(
        node=dict(
            pad=20,
            thickness=25,
            line=dict(color="white", width=2),
            label=all_nodes,
            color=node_colors,
            customdata=[node.replace(' [entrada]', '').replace(' [salida]', '').replace(' [p√°gina]', '').replace(' ‚Üê', '').replace(' ‚Üí', '') for node in all_nodes],
            hovertemplate='%{customdata}<br>%{value} sesiones<extra></extra>'
        ),
        link=dict(
            source=all_sources,
            target=all_targets,
            value=all_values,
            color="rgba(0, 0, 0, 0.2)",
            hovertemplate='%{value} sesiones<extra></extra>'
        )
    )])
    
    fig_sankey.update_layout(
        title=f"Diagrama de Flujo de Navegaci√≥n (Top {num_routes} Rutas)",
        height=800,
        font=dict(size=11, family="Arial"),
        plot_bgcolor='white',
        paper_bgcolor='white'
    )
    
    st.plotly_chart(fig_sankey, use_container_width=True)
    
    # Leyenda de colores
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("üü¢ **Verde**: P√°ginas de entrada")
    with col2:
        st.markdown("üîµ **Azul**: P√°ginas intermedias")
    with col3:
        st.markdown("üî¥ **Rojo**: P√°ginas de salida")
    
    # Insights clave
    st.subheader("üí° Insights Clave")
    
    # Calcular m√©tricas de insight
    entrance_rate = (df[df['previous_page'] == '(entrance)']['session_count'].sum() / total_sessions * 100)
    exit_rate = (df[df['next_page'] == '(exit)']['session_count'].sum() / total_sessions * 100)
    
    top_entrance = entrance_pages.iloc[0] if len(entrance_pages) > 0 else None
    top_exit = exit_pages.iloc[0] if len(exit_pages) > 0 else None
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**üìç P√°ginas de Entrada:**")
        st.metric("% de Sesiones que Inician", f"{entrance_rate:.1f}%")
        if top_entrance is not None:
            st.write(f"**P√°gina m√°s com√∫n:** {top_entrance['current_page_short']}")
            st.write(f"**Sesiones:** {top_entrance['session_count']:,}")
    
    with col2:
        st.write("**üö™ P√°ginas de Salida:**")
        st.metric("% de Sesiones que Terminan", f"{exit_rate:.1f}%")
        if top_exit is not None:
            st.write(f"**P√°gina m√°s com√∫n:** {top_exit['current_page_short']}")
            st.write(f"**Sesiones:** {top_exit['session_count']:,}")
    
    # Rutas cr√≠ticas
    st.write("**üéØ Rutas Cr√≠ticas para Optimizaci√≥n:**")
    
    # Rutas con alta salida despu√©s de p√°gina actual
    critical_exits = df[
        (df['next_page'] == '(exit)') & 
        (df['previous_page'] != '(entrance)')
    ].nlargest(5, 'session_count')
    
    if not critical_exits.empty:
        st.write("*Usuarios que abandonan despu√©s de estas secuencias:*")
        for _, row in critical_exits.iterrows():
            st.write(f"- **{shorten_url(row['previous_page'])}** ‚Üí **{shorten_url(row['current_page'])}** ‚Üí (salida): {row['session_count']:,} sesiones")
    
    # Bot√≥n de descarga
    if st.button("üì• Descargar Datos CSV", key="download_session_paths"):
        csv = df.to_csv(index=False)
        st.download_button(
            label="Descargar CSV",
            data=csv,
            file_name="session_path_analysis.csv",
            mime="text/csv"
        )

def mostrar_low_converting_sessions(df):
    """Visualizaci√≥n para Low Converting Sessions Analysis"""
    st.subheader("üîç An√°lisis de Sesiones con Baja Conversi√≥n")
    
    if df.empty:
        st.warning("No hay datos de sesiones sin conversi√≥n para el rango seleccionado")
        return
    
    # M√©tricas generales
    total_sessions = df['total_non_converting_sessions'].sum()
    total_users = df['unique_users'].sum()
    avg_duration = (df['avg_session_duration_seconds'] * df['total_non_converting_sessions']).sum() / total_sessions
    avg_page_views = (df['avg_page_views'] * df['total_non_converting_sessions']).sum() / total_sessions
    avg_bounce = (df['pct_bounced_sessions'] * df['total_non_converting_sessions']).sum() / total_sessions
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Sesiones Sin Conversi√≥n", f"{total_sessions:,}")
    with col2:
        st.metric("Usuarios √önicos", f"{total_users:,}")
    with col3:
        st.metric("Duraci√≥n Media", f"{avg_duration:.0f}s")
    with col4:
        st.metric("Tasa Bounce Media", f"{avg_bounce:.1f}%")
    
    # Mostrar tabla con datos
    st.subheader("üìä Datos Detallados")
    
    # Crear columnas seleccionables para mostrar
    columnas_mostrar = st.multiselect(
        "Seleccionar columnas a mostrar:",
        options=list(df.columns),
        default=['session_source', 'session_medium', 'device_category', 
                 'total_non_converting_sessions', 'avg_page_views', 
                 'avg_session_duration_seconds', 'pct_bounced_sessions']
    )
    
    if columnas_mostrar:
        st.dataframe(df[columnas_mostrar].head(50).style.format({
            'total_non_converting_sessions': '{:,}',
            'unique_users': '{:,}',
            'avg_page_views': '{:.2f}',
            'avg_unique_events': '{:.2f}',
            'avg_session_duration_seconds': '{:.2f}',
            'avg_engagement_time_seconds': '{:.2f}',
            'pct_low_engagement': '{:.2f}%',
            'pct_bounced_sessions': '{:.2f}%'
        }))
    
    # An√°lisis por fuente de tr√°fico
    st.subheader("üåê An√°lisis por Fuente de Tr√°fico")
    
    traffic_analysis = df.groupby(['session_source', 'session_medium']).agg({
        'total_non_converting_sessions': 'sum',
        'avg_page_views': 'mean',
        'pct_bounced_sessions': 'mean'
    }).reset_index().sort_values('total_non_converting_sessions', ascending=False).head(15)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Gr√°fico de barras - Top fuentes sin conversi√≥n
        fig_sources = px.bar(
            traffic_analysis,
            x='total_non_converting_sessions',
            y='session_source',
            orientation='h',
            color='pct_bounced_sessions',
            title='Top 15 Fuentes con M√°s Sesiones Sin Conversi√≥n',
            labels={
                'total_non_converting_sessions': 'Sesiones',
                'session_source': 'Fuente',
                'pct_bounced_sessions': 'Bounce %'
            },
            color_continuous_scale='Reds'
        )
        fig_sources.update_layout(yaxis={'categoryorder': 'total ascending'}, height=500)
        st.plotly_chart(fig_sources, use_container_width=True)
    
    with col2:
        # Scatter: Bounce vs Page Views
        fig_scatter = px.scatter(
            traffic_analysis,
            x='avg_page_views',
            y='pct_bounced_sessions',
            size='total_non_converting_sessions',
            color='session_medium',
            hover_name='session_source',
            title='Bounce Rate vs Page Views por Fuente',
            labels={
                'avg_page_views': 'Page Views Promedio',
                'pct_bounced_sessions': 'Bounce Rate (%)',
                'total_non_converting_sessions': 'Sesiones',
                'session_medium': 'Medio'
            }
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    # An√°lisis por dispositivo
    st.subheader("üì± An√°lisis por Dispositivo")
    
    device_analysis = df.groupby('device_category').agg({
        'total_non_converting_sessions': 'sum',
        'avg_session_duration_seconds': 'mean',
        'pct_bounced_sessions': 'mean',
        'avg_page_views': 'mean'
    }).reset_index()
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Pie chart - Distribuci√≥n por dispositivo
        fig_device_pie = px.pie(
            device_analysis,
            values='total_non_converting_sessions',
            names='device_category',
            title='Distribuci√≥n de Sesiones Sin Conversi√≥n por Dispositivo',
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        st.plotly_chart(fig_device_pie, use_container_width=True)
    
    with col2:
        # Barras agrupadas - M√©tricas por dispositivo
        fig_device_metrics = go.Figure()
        
        fig_device_metrics.add_trace(go.Bar(
            x=device_analysis['device_category'],
            y=device_analysis['avg_session_duration_seconds'],
            name='Duraci√≥n (seg)',
            marker_color='lightblue'
        ))
        
        fig_device_metrics.add_trace(go.Bar(
            x=device_analysis['device_category'],
            y=device_analysis['pct_bounced_sessions'],
            name='Bounce Rate (%)',
            marker_color='salmon',
            yaxis='y2'
        ))
        
        fig_device_metrics.update_layout(
            title='M√©tricas por Tipo de Dispositivo',
            xaxis_title='Dispositivo',
            yaxis=dict(title='Duraci√≥n Sesi√≥n (seg)'),
            yaxis2=dict(title='Bounce Rate (%)', overlaying='y', side='right'),
            barmode='group'
        )
        
        st.plotly_chart(fig_device_metrics, use_container_width=True)
    
    # An√°lisis de Landing Pages problem√°ticas
    st.subheader("üö™ Landing Pages con Mayor Tasa de No Conversi√≥n")
    
    landing_analysis = df.groupby('landing_page').agg({
        'total_non_converting_sessions': 'sum',
        'avg_page_views': 'mean',
        'pct_bounced_sessions': 'mean',
        'avg_engagement_time_seconds': 'mean'
    }).reset_index().sort_values('total_non_converting_sessions', ascending=False).head(20)
    
    # Acortar URLs para mejor visualizaci√≥n
    landing_analysis['landing_page_short'] = landing_analysis['landing_page'].apply(
        lambda x: x[:50] + '...' if len(str(x)) > 50 else x
    )
    
    fig_landing = px.bar(
        landing_analysis.head(10),
        x='total_non_converting_sessions',
        y='landing_page_short',
        orientation='h',
        color='pct_bounced_sessions',
        title='Top 10 Landing Pages con M√°s Sesiones Sin Conversi√≥n',
        labels={
            'total_non_converting_sessions': 'Sesiones Sin Conversi√≥n',
            'landing_page_short': 'Landing Page',
            'pct_bounced_sessions': 'Bounce %'
        },
        color_continuous_scale='Oranges',
        hover_data={'landing_page': True}
    )
    fig_landing.update_layout(yaxis={'categoryorder': 'total ascending'}, height=500)
    st.plotly_chart(fig_landing, use_container_width=True)
    
    # An√°lisis geogr√°fico
    st.subheader("üåç An√°lisis Geogr√°fico")
    
    geo_analysis = df.groupby(['country', 'city']).agg({
        'total_non_converting_sessions': 'sum',
        'avg_page_views': 'mean',
        'pct_bounced_sessions': 'mean'
    }).reset_index().sort_values('total_non_converting_sessions', ascending=False).head(20)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Top pa√≠ses
        country_stats = df.groupby('country').agg({
            'total_non_converting_sessions': 'sum'
        }).reset_index().sort_values('total_non_converting_sessions', ascending=False).head(10)
        
        fig_countries = px.bar(
            country_stats,
            x='country',
            y='total_non_converting_sessions',
            title='Top 10 Pa√≠ses con Sesiones Sin Conversi√≥n',
            labels={
                'country': 'Pa√≠s',
                'total_non_converting_sessions': 'Sesiones'
            },
            color='total_non_converting_sessions',
            color_continuous_scale='Reds'
        )
        fig_countries.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_countries, use_container_width=True)
    
    with col2:
        # Tabla de ciudades
        st.write("**Top 15 Ciudades:**")
        st.dataframe(geo_analysis.head(15).style.format({
            'total_non_converting_sessions': '{:,}',
            'avg_page_views': '{:.2f}',
            'pct_bounced_sessions': '{:.2f}%'
        }))
    
    # Insights y recomendaciones
    st.subheader("üí° Insights Clave")
    
    # Identificar problemas
    high_bounce = df[df['pct_bounced_sessions'] > 70].nlargest(5, 'total_non_converting_sessions')
    low_engagement = df[df['pct_low_engagement'] > 70].nlargest(5, 'total_non_converting_sessions')
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**üö® Fuentes con Mayor Bounce Rate (>70%):**")
        if not high_bounce.empty:
            for _, row in high_bounce.iterrows():
                st.write(f"- **{row['session_source']}** / {row['session_medium']}: {row['pct_bounced_sessions']:.1f}% bounce ({row['total_non_converting_sessions']:,} sesiones)")
        else:
            st.write("‚úÖ No hay fuentes con bounce rate cr√≠tico")
    
    with col2:
        st.write("**‚è±Ô∏è Fuentes con Bajo Engagement (>70%):**")
        if not low_engagement.empty:
            for _, row in low_engagement.iterrows():
                st.write(f"- **{row['session_source']}** / {row['session_medium']}: {row['pct_low_engagement']:.1f}% bajo engagement")
        else:
            st.write("‚úÖ No hay fuentes con engagement cr√≠tico")
    
    # Bot√≥n de descarga
    if st.button("üì• Descargar Datos CSV", key="download_low_converting"):
        csv = df.to_csv(index=False)
        st.download_button(
            label="Descargar CSV",
            data=csv,
            file_name="low_converting_sessions.csv",
            mime="text/csv"
        )
